# 自动映射比对使用说明

## 1. 加速库算子与torch模型算子的自动映射比对

### 使用方法

使用方法分为四步：

1. dump torch模型算子tensor及拓扑信息
2. dump加速库算子tensor及拓扑信息
3. 手动添加自定义算子映射（若不指定则使用内置算子映射）
4. 将dump目录及算子类型映射字典文件的目录作为入参输入到ait llm compare中完成比对

### 第一步：dump torch模型算子tensor及拓扑信息

#### DumpConfig

接口说明：dump数据配置类，可用于按需dump模型数据。

接口原型：DumpConfig(dump_path, token_range, module_list, tensor_part)

| 参数名         | 含义                   | 使用说明                                                                                                                                 | 是否必填 |
| -------------- | ---------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | -------- |
| dump_path      | 设置dump的数据路径     | 数据类型：str，默认为当前目录。                                                                                                          | 否       |
| token_range    | 需要dump的token列表    | 数据类型：list。默认为[0]，只dump第0个token的数据。                                                                                      | 否       |
| module_list    | 指定要hook的module类型 | 数据类型：list，默认为[]，即dump所有module的数据。                                                                                       | 否       |
| tensor_part    | 指定要dump哪部分数据   | 数据类型：int，默认为2。当tensor_part=0时，只dump输入数据；当tensor_part=1时，只dump输出数据； 当tensor_part=2时，dump输入和输出的数据。 | 否       |
| device_id | 指定要dump的device id  | 数据类型：int，默认为None 表示不限制 device。如指定 device_id=1，将跳过其他 device 的 dump。                                        | 否       |

#### register_hook

接口说明：给模型添加hook，用于dump数据

接口原型：register_hook(model, config, hook_name=”dump_data”)

| 参数名    | 含义           | 使用说明                                                | 是否必填 |
| --------- | -------------- | ------------------------------------------------------- | -------- |
| model     | 需要hook的模型 | 数据类型：torch.nn.Module，建议设置为最外层的torch模型  | 是       |
| config    | Hook配置       | 数据类型：DumpConfig                                    | 是       |
| hook_type | hook类型       | 数据类型：str，默认值为dump_data，当前仅支持dump_data。 | 否       |

#### 使用方式

```
from ait_llm import DumpConfig, register_hook #在模型py文件中文件开头导入DumpConfig和register_hook
dump_config = DumpConfig(dump_path="./torch_dump") 
register_hook(model, dump_config)  # model是要dump中间tensor的模型实例，在模型初始化后添加代码
```

* dump默认落盘路径`{DUMP_DIR}`在当前目录下，如果指定`dump_path`目录，落盘路径则为指定的`{DUMP_PATH_DIR}`。
* dump完成后tensor信息生成在`{DUMP_DIR}/{PID}_npu{device_id}/{TID}`目录下
* dump完成后model拓扑信息`model_tree.json`生成在`{DUMP_DIR}/{PID}_npu{device_id}`目录下

注：`device_id`为设备号；`PID`为进程号；`TID`为`token_id`

#### FAQ
1. WARNING - Unrecognized data type <class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>, cannot be saved in path ..

   如果遇到该警告导致没有数据dump下来，请检查模型py文件是否正确使用了torch模型

### 第二步：dump加速库算子tensor及拓扑信息

#### 使用方式

`ait llm dump --exec "bash run.sh patches/models/modeling_xxx.py" --type tensor model`

* dump默认落盘路径`{DUMP_DIR}`在当前目录下，如果指定`output`目录，落盘路径则为指定的`{OUTPUT_DIR}`。
* `--exec`参数是指定拉起执行大模型推理脚本的命令
* `--type tensor model`参数是指定dump模型的tensor及model拓扑信息
* dump完成后tensor信息生成在`{DUMP_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}`目录下
* dump完成后model拓扑信息生成在`{DUMP_DIR}/ait_dump/model/{PID}`目录下。由于model由layer组合而成，因此使用model时，默认同时会落盘layer信息。

### 第三步：手动添加自定义算子映射

#### 使用方式
在`op_mapping_file_dir`目录新建算子类型映射字典文件`op_mapping_file.json`

文件内容示例：  
```
{
    "LayerNormOperation": "LayerNorm",
    "LinearOperation": "Linear",
    "CommonLayer_outtensor0": ["GLMBlock_output_0", "BloomBlock_output_0"],
    "MlpGateLayerV2":["BloomMLP", "MLP"],
    "RmsNormOperation":["RMSNorm"],
    "SelfAttentionOperation":["CoreAttention"]
}
```
* 字典键为atb算子类型；值为对应的torch算子类型，可为string或list类型
* 若tensor数不唯一，可在下划线后添加tensor文件名指定tensor映射关系
* 用户指定的算子映射会在内置算子映射的基础上更新，默认使用内置算子映射

#### 内置算子映射

| 加速库算子类型 | torch算子类型 |
| ------------- | ------------ |
| LayerNormOperation | LayerNorm |
| LinearOperation | Linear |
| CommonLayer_outtensor0 | GLMBlock_output_0 (ChatGLM2 6b)<br>BloomBlock_output_0 (Bloom 7b) |
| MlpGateLayerV2 | MLP (ChatGLM2 6b)<br>BloomMLP (Bloom 7b) |
| RmsNormOperation | RMSNorm |
| SelfAttentionOperation | CoreAttention (ChatGLM2 6b)|

(扩充中...）

### 第四步：将dump目录及算子类型映射字典文件的目录作为入参输入到ait llm compare中完成比对

#### 使用方式

`ait llm compare -gp torch_dump/{PID}_npu{device_id}/{TID}/ -mp ait_dump/tensors/{device_id}_{PID}/{TID}/ --op-mapping-file xx/xxx/xx/`

#### 参数说明

| 参数名             | 描述                                                                                      | 是否必选 |
| ------------------ | ----------------------------------------------------------------------------------------- | -------- |
| --golden-path, -gp | 标杆数据torch模型算子tensor路径                                                             | 是       |
| --my-path, -mp     | 待比较的atb算子tensor路径                                                                   | 是       |
| --op-mapping-file, -mf | 算子类型映射字典文件`op_mapping_file.json`所在目录                                       | 否       |
| --log-level, -l    | 日志级别，默认为info                                                                        | 否       |
| --output, -o       | 比较结果csv的输出路径，默认为当前路径                                                         | 否       |

#### 功能说明

* ait llm compare提供有精度问题的数据与标杆数据之间的比对能力。
* --golden-path参数为第一步中 `torch_tensor`所在目录 `{DUMP_DIR}/{PID}_npu{device_id}/{TID}/`
* --my-path参数为第二步中 `atb_tensor`所在目录 `{DUMP_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}/`
* --op-mapping-file参数为第三步中算子类型映射字典文件`op_mapping_file.json`所在目录`op_mapping_file_dir`，若目录下无法找到`op_mapping_file.json`文件则使用内置算子映射
* 完成比对后会在 `output_dir`下生成一个 `ait_cmp_report_{TIMESTAMP}.csv`，保存比对的最终结果。