# 自动映射比对使用说明

# 1. 加速库算子与 torch 模型算子的自动映射比对

## 自动对比思路

使用方法分为四步：

1. dump torch 模型算子 tensor 及拓扑信息
2. dump 加速库算子 tensor 及拓扑信息
3. 手动添加自定义算子映射（若不指定则使用内置算子映射）
4. 将 dump 目录及算子类型映射字典文件的目录作为入参输入到 ait llm compare 中完成比对

## 第一步：dump torch 模型算子 tensor 及拓扑信息

```python
from ait_llm import DumpConfig, register_hook #在模型py文件中文件开头导入DumpConfig和register_hook

dump_config = DumpConfig(dump_path="./torch_dump")
register_hook(model, dump_config)  # model是要dump中间tensor的模型实例，在模型初始化后添加代码

```

> DumpConfig 支持指定 dump 路径，还可以减小 dump 数据范围，包括指定需要 dump 的 token 列表，要 hook 的 module 类型，指定 dump 算子输入还是输出，等。详见[《在线推理 DUMP 功能使用说明》](./在线推理DUMP功能使用说明.md#dumpconfig)

> dump 数据路径：
> - dump 默认落盘路径`{DUMP_DIR}`在当前目录下，可以通过配置`dump_path`指定落盘路径。
> - tensor 信息落盘位置：在`{DUMP_DIR}/{PID}_npu{device_id}/{TID}`目录下
> - model 拓扑信息落盘位置：生成在`{DUMP_DIR}/{PID}_npu{device_id}/model_tree.json`文件中
> 注：`device_id`为设备号；`PID`为进程号；`TID`为`token_id`


## 第二步：dump 加速库算子 tensor 及拓扑信息

### 使用方式

`ait llm dump --exec "bash run.sh patches/models/modeling_xxx.py" --type tensor model`

> - `--exec`参数是指定拉起执行大模型推理脚本的命令
> - `--type tensor model`参数是指定 dump 模型的 tensor 及 model 拓扑信息
> - 更多参数，可以参考[加速库DUMP功能使用说明](./加速库DUMP功能使用说明.md)

> - dump 默认落盘路径`{DUMP_DIR}`在当前目录下，如果指定`output`目录，落盘路径则为指定的`{OUTPUT_DIR}`。
> - tensor 信息落盘位置：在`{DUMP_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}`目录下
> - model 拓扑信息落盘位置：在`{DUMP_DIR}/ait_dump/model/{PID}`目录下。由于 model 由 layer 组合而成，因此使用 model 时，默认同时会落盘 layer 信息。

## 第三步：手动添加自定义算子映射（可选）

### 使用方式

在`op_mapping_file_dir`目录新建算子类型映射字典文件`op_mapping_file.json`

文件内容示例：

```
{
    "LayerNormOperation": "LayerNorm",
    "LinearOperation": "Linear",
    "CommonLayer_outtensor0": ["GLMBlock_output_0", "BloomBlock_output_0"],
    "MlpGateLayerV2":["BloomMLP", "MLP"],
    "RmsNormOperation":["RMSNorm"],
    "SelfAttentionOperation":["CoreAttention"]
}
```

- 字典键为 atb 算子类型；值为对应的 torch 算子类型，可为 string 或 list 类型
- 若 tensor 数不唯一，可在下划线后添加 tensor 文件名指定 tensor 映射关系
- 用户指定的算子映射会在内置算子映射的基础上更新，默认使用内置算子映射

### 内置算子映射

| 加速库算子类型         | torch 算子类型                                                    |
| ---------------------- | ----------------------------------------------------------------- |
| LayerNormOperation     | LayerNorm                                                         |
| LinearOperation        | Linear                                                            |
| CommonLayer_outtensor0 | GLMBlock_output_0 (ChatGLM2 6b)<br>BloomBlock_output_0 (Bloom 7b) |
| MlpGateLayerV2         | MLP (ChatGLM2 6b)<br>BloomMLP (Bloom 7b)                          |
| RmsNormOperation       | RMSNorm                                                           |
| SelfAttentionOperation | CoreAttention (ChatGLM2 6b)                                       |

(扩充中...）

## 第四步：将 dump 目录及算子类型映射字典文件的目录作为入参输入到 ait llm compare 中完成比对

### 使用方式

```shell
ait llm compare -gp torch_dump/{PID}_npu{device_id}/{TID}/ -mp ait_dump/tensors/{device_id}_{PID}/{TID}/ --op-mapping-file xx/xxx/xx/
```

ait llm compare 提供有精度问题的数据与标杆数据之间的比对能力。
> - --golden-path 参数为第一步中 `torch_tensor`所在目录 `{DUMP_DIR}/{PID}_npu{device_id}/{TID}/`
> - --my-path 参数为第二步中 `atb_tensor`所在目录 `{DUMP_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}/`
> - --op-mapping-file 参数为第三步中算子类型映射字典文件`op_mapping_file.json`所在目录`op_mapping_file_dir`，若目录下无法找到`op_mapping_file.json`文件则使用内置算子映射
> - 完成比对后会在 `output_dir`下生成一个 `ait_cmp_report_{TIMESTAMP}.csv`，保存比对的最终结果。
