# opcheck精度预检功能使用指南
## 1. 环境准备

***若不需要重新执行加速库单算子推理，可跳过步骤1***

### 1.1 cann包与atb包
```
source ./Ascend/ascend-toolkit/set_env.sh
source ./atb/set_env.sh
```
## 1.2 libopchecker.so包
libopchecker.so包需要手动编译。

首先，进入llm所在目录：
- 若为源码安装，则进入源码目录，即`ait/ait/components/llm/llm`
- 若为pip安装，则进入安装目录，安装目录通过`python3 -c 'import llm, os; print(os.path.dirname(os.path.abspath(llm.__file__)))'`确定

然后，执行以下命令以完成编译：
```
cd opcheck/test_framework && bash build.sh
```
注：libopchecker.so为预检底层，默认不打印日志，如确需启用其日志，可以执行`export LIB_OPCHECKER_LOG_ON=1`命令，设置为非1则日志恢复关闭状态。

## 2. 输入数据
### 2.1 数据落盘
使用`ait llm dump --exec "bash run.sh patches/models/modeling_xxx.py" --type tensor op`将模型推理过程中的tensor数据及算子信息落盘，-ids可指定索引，-opname可指定算子类型，-o可指定输出目录。
Dump默认落盘路径 `{DUMP_DIR}`在当前目录下，如果指定output目录，落盘路径则为指定的 `{OUTPUT_DIR}`。

- tensor信息会生成在默认落盘路径的atb_temp目录下，具体路径是 `{DUMP_DIR}/{PID}_{TID}`目录下。
- 算子信息会生成在默认落盘路径的ait_dump目录下，具体路径是 `{DUMP_DIR}/ait_dump/operation_io_tensors/{PID}/operation_tensors_{executeCount}.csv`。

注：`{PID}`为进程号；`{TID}`为 `token_id`；`{executeCount}`为 `operation`运行次数。

### 2.2 打开算子信息文件

***若不需要打开算子信息csv文件，可跳过步骤2.2和2.3***

1. 打开Excel数据标签页，选择`从文本/CSV`导入数据

![图片1](image/%E7%B2%BE%E5%BA%A6%E9%A2%84%E6%A3%80%E8%83%BD%E5%8A%9B%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/bc7316f0-470c-454f-b9f5-d83429c4e062.png)

2. 选中算子信息文件后，设置分隔符为`——自定义——` `|`，点击加载

![输入图片说明](image/%E7%B2%BE%E5%BA%A6%E9%A2%84%E6%A3%80%E8%83%BD%E5%8A%9B%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/7bcb6c78-a839-4dad-bb0a-4abcba10694c.png)

### 2.3 算子信息文件各列说明
|   表头   | 说明 |
| -------- | -------------------------------------------------- |
| CaseNum | 用例编号 ，从1开始，不允许跳变 |
| CaseName | 用例名称，无约束，一般体现算子名称 |
| OpName   | 算子名称，需要包含算子类名和以'_'分隔的算子拓扑结构名，示例：LinearOperation_1_1_0_0 |
| OpParam  | 算子参数，json格式 |
| InNum | intersor数量 |
| InDType | 各个intensor的数据类型，以';'分隔，取值范围：float, float16, int8, int32, uint8, int16, uint16, uint32, int64, uint64, double, bool, string, complex64, complex128, bf16 |
| InFormat | 各个intensor的格式，以';'分隔 |
| InShape | 各个intensor的shape，以';'分隔，单个shape维度之间以','分隔 |
| OutNum | outtensor的数量 |
| OutDType | 各个outtensor的数据类型，以';'分隔，取值范围：float, float16, int8, int32, unit8, int16, uint16, uint32, int64, uint64, double, bool, string, complex64, complex128, bf16 |
| OutFormat | 各个outtensor的格式，约束同InFormat |
| OutShape | 各个outtensor的shape，约束同InShape |
| DataGenType | 各个intensor数据生成方式，以';'分隔，默认为customize |
| DataGenRange | 各个intensor数据生成范围，以';'分隔，默认为空 |
| InTensorFile | 各个intersor的路径，以';'分隔 |
| OutTensorFile | 各个outtersor的路径，以';'分隔 |
| TestType | 测试类型，默认为空 |
| TestLevel | 测试级别，默认为空 |
| FromModel | 测试用例来源模型，默认为空 |
| SocVersion | 硬件平台，默认为空 |
| ExpectedError | 用例预期错误，默认为NO_ERROR |

## 3. 执行精度预检
### 3.1 使用示例
`ait llm opcheck -i {DUMP_DIR}/{PID}_{TID}/0/ -c {DUMP_DIR}/ait_dump/operation_io_tensors/{PID}/operation_tensors_{executeCount}.csv`
命令参数说明请参考[llm大模型推理精度工具功能说明_v0.2.1.md](./llm大模型推理精度工具功能说明_v0.2.1.md)

### 3.2 输出文件各列说明
|   表头   | 说明 |
| -------- | -------------------------------------------------- |
| op_id    | 算子id，以'_'分隔的算子拓扑结构名（从输入算子信息表中获取） |
| op_name  | 算子名称，格式为算子类名（参见[atb/infer_op_params.h中的Operation](https://www.hiascend.com/document/detail/zh/canncommercial/700/foundmodeldev/ascendtb/ascendtb_01_0045.html)） |
| op_param | 算子参数，同OpParam |
| tensor_path | 算子输入intensor的目录 |
| out_tensor_id |  算子输出outtensor的序号（部分算子输出可能有多个outtensor） |
| precision_standard | 采用的精度标准（参见3.3精度标准）|
| excuted_information | 运行结果，execution successful为精度通过，execution failed为精度不通过或者算子执行失败，addition failed为算子添加失败（不支持该算子类型）|
| precision_result(%) | 实际的精度通过率（使用相对误差，全部通过则为100%）|
| max_rel_error | 最大的相对误差值 |
| abs_precision_result(%) | 实际的绝对误差精度通过率 |
| max_abs_error | 最大的绝对误差值 |
| cosine_similarity | 余弦相似度 |
| kl_divergence | kl散度 |

注：后四列为可选项，可通过参数`-metric`指定
### 3.3 精度标准
每个DataType共有两项数据共同形成精度标准，其中第一项为误差级别，第二项为满足条件。例如，double对应的精度标准是满足Error小于0.0001误差级别的数据比例在99.99%以上，即双万分之一。
```
        self.precision_standard = {
            'double': [error1, 99.99], 'uint32': [error1, 99.99], 
            'int64': [error1, 99.99], 'float': [error1, 99.99], 'int32': [error1, 99.99], 
            'uint64': [error1, 99.99], 'float16': [error3, 99.9], 'bf16': [error4, 99.6], 
            'int8': [error6, 99.9], 'uint8': [error6, 99], 'int16': [error6, 99.9], 
            'uint16': [error6, 99.9], 'bool': [error1, 100]
        }
```
注：如果使用旧版atb，落下的DataType可能为大写格式（示例：`ACL_DOUBLE`）

## 3. 精度预检算子用例支持情况
| 算子名称 | Ascend310P | Ascend910B |
| -------- | --------- | ---------- |
| ActivationOperation | 不支持 | 支持 |
| AllGatherOperation | 不支持 | 支持 |
| AllReduceOperation | 不支持 | 支持 |
| BroadcastOperation | 不支持 | 支持 |
| ConcatOperation | 支持 | 支持 |
| CumsumOperation | 支持 | 支持 |
| ElewiseOperation | 支持 | 支持 |
| FastSoftMaxOperation | 不支持 | 支持 |
| FastSoftMaxOperation | 不支持 | 支持 |
| FillOperation | 支持 | 支持 |
| GatherOperation | 支持 | 支持 |
| GenAttentionMaskOperation | 支持 | 支持 |
| KvCacheOperation | 不支持 | 支持 |
| LinearOperation | 支持 | 支持 |
| LinearQuantOperation | 支持 | 支持 |
| LinearActivationOperation | 不支持 | 支持 |
| LinearActivationQuantOperation | 不支持 | 支持 |
| LinearParallelOperation | 不支持 | 支持 |
| LinearSparseOperation | 支持 | 不支持 |
| MatmulOperation | 支持 | 支持 |
| PadOperation | 支持 | 支持 |
| PagedAttentionOperation | 不支持 | 支持 |
| RepeatOperation | 支持 | 支持 |
| ReshapeAndCacheOperation | 不支持 | 支持 |
| RmsNormOperation | 不支持 | 支持 |
| RopeOperation | 支持 | 支持 |
| RopeGradOperation | 支持 | 支持 |
| SelfAttentionOperation | 不支持 | 支持 |
| SetValueOperation | 支持 | 支持 |
| SliceOperation | 支持 | 支持 |
| SoftmaxOperation | 支持 | 支持 |
| SortOperation | 支持 | 支持 |
| SplitOperation | 支持 | 支持 |
| StridedBatchMatmulOperation | 支持 | 支持 |
| TopkToppSamplingOperation | 支持 | 支持 |
| TransposeOperation | 支持 | 支持 |
| UnpadOperation | 支持 | 支持 |
| AsStridedOperation | 支持 | 支持 |
| LayerNormOperation | 支持 | 支持 |
| MultinomialOperation | 支持 | 支持 |
| ReduceOperation | 支持 | 支持 |
| TransdataOperation | 支持 | 支持 |
| WhereOperation | 支持 | 支持 |

*注：此为精度预检用例支持设备，算子支持设备请查询atb相关文档